#####数据分析  数据清洗
#

#pandas.merge 将数据框的行连接起来
#pandas.concat  将多个对象堆叠
#combine_first  数据填充

df1=pd.DataFrame({'key':['b','b','a','c','a','a','b'],'data1':range(7)})

df2=pd.DataFrame({'key':['a','b','d'],'data2':range(3)})

pd.merge(df1,df2) #合并和展示重叠数据所在的行  默认是inner 就是交集

pd.merge(df1,df2,on='key') ###制定连接的行

df3=pd.DataFrame({'lkey':['b','b','a','c','a','a','b'],'data1':range(7)})
df4=pd.DataFrame({'rkey':['a','b','d'],'data2':range(3)})
###两个不同名字的列，有相同元素也可以连接
pd.merge(df3,df4,left_on='lkey',right_on='rkey')

##跟R plyr包的join一样以及sql 可以定义 左连接右连接 全连接 内连接 外连接
pd.merge(df1,df2,how='outer')

##根据多个键进行合并
left=pd.DataFrame({'key1':['foo','foo','bar'],'key2':['one','two','one'],'lval':[1,2,3]})
right=pd.DataFrame({'key1':['foo','foo','bar','bar'],'key2':['one','one','one','two'],'rval':[4,5,6,7]})
pd.merge(left,right,on=['key1','key2'],how='outer')
pd.merge(left,right,on='key1',suffixes=('_left','_right'))

####索引上的合并
left1=DataFrame({'key':['a','b','a','a','b','c'],'value':range(6)})
right1=DataFrame({'group_val':[3.5,7]},index=['a','b'])
pd.merge(left1,right1,left_on='key',right_index=True) #通过索引来连接
pd.merge(left1,right1,left_on='key',right_index=True,how='outer')

###层次化索引的数据
lefth=pd.DataFrame({'key1':['ohio','ohio','ohio','nevada','nevada'],'key2':
[2000,2001,2002,2001,2002],'data':np.arange(5.)})
righth=pd.DataFrame(np.arange(12).reshape((6,2)),index=[['nevada','nevada','ohio','ohio','ohio','ohio'],
[2001,2000,2000,2000,2001,2002]],columns=['event1','event2'])
pd.merge(lefth,righth,left_on=['key1','key2'],right_index=True)

#####join函数
left2.join(right2,how='outer') ##也可以合并，但是只能左连接
left1.join(right1,on='key')  #也可以用索引连接

another=DataFrame([7.,8.],[9.,10.],[11.,12.],[16.,17.]],index=['a','c','e','f'],columns=['new york','oregon'])
lift2.join([right2,another])  #合并表格，对照索引
left2.join([right2,another],how='outer')  #全连接，缺失值变成na


#######
##########轴向连接，称为连接、绑定或堆叠
#numpy中有 concatenation函数
arr=np.arange(12).reshape((3,4))
np.concatenate([arr,arr],axis=1)  ###直接横向连接 变成6*3
##pandas 的用法 concat
s1=Series([0,1],index=['a','b'])
s2=Series([2,3,4],index=['c','d','e'])
s3=Series([5.6],index=['f','g'])
pd.concat([s1,s2,s3])
pd.concat([s1,s2,s3],axis=1)
s4=pd.concat([s1*5,s3])
pd.concat([s1,s4],axis=1)
pd.concat([s1,s4],axis=1,join='inner')
pd.concat([s1,s4],axis=1,join_axes=[['a','c','b','e']])
result=pd.concat([s1,s1,s3],keys=['one','two','three'])
pd.concat([s1,s2,s3],axis=1,keys=['one','two','three']) ##把轴换了，就可以

######
df1=DataFrame(np.arange(6).reshape(3,2),index=['a','b','c'],columns=['one','two'])
df2=DataFrame(5+np.arange(4).reshape(2,2),index=['a','c'],columns=['three','four'])
pd.concat([df1,df2],axis=1,keys=['level1','level2'])
###
####如果传入字典，字典的键会被当成key值
pd.concat({'level1':df1,'level2':df2},axis=1)

##产生一组新索引
df1=DataFrame(np.random.randn(3,4),columns=['a','b','c','d'])
df2=DataFrame(np.random.randn(2,3),columns=['b','d','a'])

pd.concat([df1,df2],ignore_index=True)

#####
######合并重叠数据
a=pd.Series([np.nan,2.5,np.nan,3.5,4.5,np.nan],index=['f','e','d','c','b','a'])
b=pd.Series(np.arange(len(a),dtype=np.float64),index=['f','e','d','c','b','a'])
b[-1]=np.nan  
np.where(pd.isnull(a),b,a)
b{:-2].combine_first(a[2:])

df1=pd.DataFrame({'a':[1.,np.nan,5.,np.nan],'b':[np.nan,2.,np.nan,6.],'c':range(2,18,4)})
df2=pd.DataFrame({'a':[5.,4.,np.nan,3.,7.],'b':[np.nan,3.,4.,6.,8.]})

df1.combine_first(df2)###1里面缺失的数据用2中补齐

#### 重塑和轴向旋转
##重塑层次化索引
data=pd.DataFrame(np.arange(6).reshape((2,3)),index=pd.Index(['ohio','colorado'],name='state'),
columns=pd.Index(['one','two','three'],name='namber'))

result=data.stack()  #转置
result.unstack()  ##重新转置 回数据框
data2.unstack().stack()  ####可以滤除数据
data2.unstack().stack(dropna=False) ##不剔除
####注：对数据框进行旋转操作时，作为旋转轴的级别将为结果中最低的级别

###时间序列数据通常是长格式，或者堆叠格式，可以转换为数据框
pivioted=ldata.pivot('date','item','value')
pivoted.head()
pivoted=ldata.pivot('date','item')###减少了最后一个参数，变成了层次化的列

#####
#######
########数据转换
#####移除重复数据
data=pd.DataFrame({'k1':['one']*3+['two']*4,'k2':[1,1,2,3,3,4,4]})
data.duplicated() ##返回一个布尔值，判断各行是否是重复行
data.drop_duplicates()  ##移除重复行

data['v1']=range(7)
data.drop_duplicates(['k1']) ##指定行过滤重复项  ps 默认所有行都判断
data.drop_duplicates({'k1','k2'],take_last=True)  ###默认保留最后一个出现值的组合

###利用函数或映射进行数据转换
data=pd.DataFrame({'food':['bacon','pulled pork','bacon','Pastrami','corned beef','bacon','pastrami','honey ham','nova lox'],'ounces':[4,3,12,6,7.5,8,3,5,6]})
meat_to_animal={'bacon':'pig','pulled pork':'pig','pastrami':'cow','corned beef':'cow','honey ham':'pig','nova lox':'salmon'}

data['animal']=data['food'].map(str.lower).map(meat_to_animal)
###用map传入一个函数

###替换值
data=pd.Series([1.,-999.,2.,-999.,-1000.,3.])
data.replace(-999,np.nan) #替换成pandas能理解的na值
data.replace(np.nan,data.mean())
data.replace([-999,-1000],np.nan)

##重命名轴索引
data=DataFrame(np.arange(12).reshape((3,4)),index=['ohio','colorado','new york'],columns=['one','two','three','four'])
data.index.map(str.upper)  #把标签换成大写
##不修改原始数据的情况
data.rename(index=str.title,columns=str.upper)
data.rename(index={'ohio':'indiana'},columns={'three':'peekaboo'})###指定重命名
##
#####数据离散化和面元划分
ages=[20,22,25,27,21,23,37,31,61,45,41,32]
bins=[18,25,35,60,100]  #界定划分标准
cats=pd.cut(ages,bins)
cats.labels  ##标签属性
cats.levels##划分区间
pd.value_counts(cats)  ##分组统计
pd.cut(ages,[18,26,36,61,100].right=False)  #修改闭区间方向
group_names=['youth','youngadult','middleages','senior']
pd.cut(ages,bins,labels=group_names)
##如果传入的是数量，则会根据最小最大值计算等长面元
data=np.random.rand(20)
pd.cut(data,4,precision=2)
##
####qcut 分位数切分
data=np.random.randn(1000) 
cats=pd.qcut(data,4)
pd.value_counts(cats)
##
######检测和过滤异常值
np.random.seed(12345)
data=pd.DataFrame(np.random.randn(1000,4))
data.describe() ##summary

col=data[3]
col[np.abs(col)>3]
data[np.abs(data)>3]
data[(np.abs(data)>3).any(1)]  ##输出满足条件的行，存在一个即可
data[np.abs(data)>3]=np.sign(data)*3 #sign函数返回1 0 或-1

######排列和随机采样
####permutation 随机重排序
df=pd.DataFrame(np.arange(5*4).reshape(5,4))
sampler=np.random.permutation(5) ##构建了一组随机排列的顺序数
df.take(sampler)  #把顺序数应用到数据框中

bag=np.array([5,7,-1,6,4])
sampler=np.random.randint(0,len(bag),size=10)  #生成的是随机正数
draws=bag.take(sampler)  #随机生成行

#计算指标/哑变量
df=pd.DataFrame({'key':['b','b','a','c','a','b'],'data1':range(6)})
pd.get_dummies(df['key'])  ##将变量变成虚拟变量
#
dummies=pd.get_dummies(df['key'],prefix='key') ###加上列名前缀
df_with_dummy=df[['data1']].join(dummies) #合并列
df_with_dummy
##
mnames=['movie_id','title','genres']
movies=pd.read_table('ch02.dat',sep='::',header=None,names=mnames)
movies[:10]
genre_iter=(set(x.split('|')) for x in movies.genres)
genres=sorted(set.union(*genre_iter))
dummies=DataFrame(np.zeros((len(movies),len(genres))),columns=genres)

for i,gen in enumerate(movies,genres):
    dummies.ix[ix,gen.split('|')]=1
###迭代将每一步电影dummies各行的项设置为1
movies_windic=movies.join(dummies.add_prefix('Genre_')) #将其与movies合并
movies_windic.ix[0] 
######j结合get_dummies和cut
values=np.random.rand(10)
bins=[0,0.2,0.4,0.6,0.8,1]
pd.get_dummies(pd.cut(values,bins))

######
########字符串操作
p228
