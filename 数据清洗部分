#####数据分析  数据清洗
#

#pandas.merge 将数据框的行连接起来
#pandas.concat  将多个对象堆叠
#combine_first  数据填充

df1=pd.DataFrame({'key':['b','b','a','c','a','a','b'],'data1':range(7)})

df2=pd.DataFrame({'key':['a','b','d'],'data2':range(3)})

pd.merge(df1,df2) #合并和展示重叠数据所在的行  默认是inner 就是交集

pd.merge(df1,df2,on='key') ###制定连接的行

df3=pd.DataFrame({'lkey':['b','b','a','c','a','a','b'],'data1':range(7)})
df4=pd.DataFrame({'rkey':['a','b','d'],'data2':range(3)})
###两个不同名字的列，有相同元素也可以连接
pd.merge(df3,df4,left_on='lkey',right_on='rkey')

##跟R plyr包的join一样以及sql 可以定义 左连接右连接 全连接 内连接 外连接
pd.merge(df1,df2,how='outer')

##根据多个键进行合并
left=pd.DataFrame({'key1':['foo','foo','bar'],'key2':['one','two','one'],'lval':[1,2,3]})
right=pd.DataFrame({'key1':['foo','foo','bar','bar'],'key2':['one','one','one','two'],'rval':[4,5,6,7]})
pd.merge(left,right,on=['key1','key2'],how='outer')
pd.merge(left,right,on='key1',suffixes=('_left','_right'))

####索引上的合并
left1=DataFrame({'key':['a','b','a','a','b','c'],'value':range(6)})
right1=DataFrame({'group_val':[3.5,7]},index=['a','b'])
pd.merge(left1,right1,left_on='key',right_index=True) #通过索引来连接
pd.merge(left1,right1,left_on='key',right_index=True,how='outer')

###层次化索引的数据
lefth=pd.DataFrame({'key1':['ohio','ohio','ohio','nevada','nevada'],'key2':
[2000,2001,2002,2001,2002],'data':np.arange(5.)})
righth=pd.DataFrame(np.arange(12).reshape((6,2)),index=[['nevada','nevada','ohio','ohio','ohio','ohio'],
[2001,2000,2000,2000,2001,2002]],columns=['event1','event2'])
pd.merge(lefth,righth,left_on=['key1','key2'],right_index=True)

#####join函数
left2.join(right2,how='outer') ##也可以合并，但是只能左连接
left1.join(right1,on='key')  #也可以用索引连接

another=DataFrame([7.,8.],[9.,10.],[11.,12.],[16.,17.]],index=['a','c','e','f'],columns=['new york','oregon'])
lift2.join([right2,another])  #合并表格，对照索引
left2.join([right2,another],how='outer')  #全连接，缺失值变成na


#######
##########轴向连接，称为连接、绑定或堆叠
#numpy中有 concatenation函数
arr=np.arange(12).reshape((3,4))
np.concatenate([arr,arr],axis=1)  ###直接横向连接 变成6*3
##pandas 的用法 concat
s1=Series([0,1],index=['a','b'])
s2=Series([2,3,4],index=['c','d','e'])
s3=Series([5.6],index=['f','g'])
pd.concat([s1,s2,s3])
pd.concat([s1,s2,s3],axis=1)
s4=pd.concat([s1*5,s3])
pd.concat([s1,s4],axis=1)
pd.concat([s1,s4],axis=1,join='inner')
pd.concat([s1,s4],axis=1,join_axes=[['a','c','b','e']])
result=pd.concat([s1,s1,s3],keys=['one','two','three'])
pd.concat([s1,s2,s3],axis=1,keys=['one','two','three']) ##把轴换了，就可以

######
df1=DataFrame(np.arange(6).reshape(3,2),index=['a','b','c'],columns=['one','two'])
df2=DataFrame(5+np.arange(4).reshape(2,2),index=['a','c'],columns=['three','four'])
pd.concat([df1,df2],axis=1,keys=['level1','level2'])
###
####如果传入字典，字典的键会被当成key值
pd.concat({'level1':df1,'level2':df2},axis=1)

##产生一组新索引
df1=DataFrame(np.random.randn(3,4),columns=['a','b','c','d'])
df2=DataFrame(np.random.randn(2,3),columns=['b','d','a'])

pd.concat([df1,df2],ignore_index=True)

#####
######合并重叠数据
a=pd.Series([np.nan,2.5,np.nan,3.5,4.5,np.nan],index=['f','e','d','c','b','a'])
b=pd.Series(np.arange(len(a),dtype=np.float64),index=['f','e','d','c','b','a'])
b[-1]=np.nan  
np.where(pd.isnull(a),b,a)
b{:-2].combine_first(a[2:])

df1=pd.DataFrame({'a':[1.,np.nan,5.,np.nan],'b':[np.nan,2.,np.nan,6.],'c':range(2,18,4)})
df2=pd.DataFrame({'a':[5.,4.,np.nan,3.,7.],'b':[np.nan,3.,4.,6.,8.]})

df1.combine_first(df2)###1里面缺失的数据用2中补齐

#### 重塑和轴向旋转
##重塑层次化索引
data=pd.DataFrame(np.arange(6).reshape((2,3)),index=pd.Index(['ohio','colorado'],name='state'),
columns=pd.Index(['one','two','three'],name='namber'))

result=data.stack()  #转置
result.unstack()  ##重新转置 回数据框
data2.unstack().stack()  ####可以滤除数据
data2.unstack().stack(dropna=False) ##不剔除
####注：对数据框进行旋转操作时，作为旋转轴的级别将为结果中最低的级别

###时间序列数据通常是长格式，或者堆叠格式，可以转换为数据框
pivioted=ldata.pivot('date','item','value')
pivoted.head()
pivoted=ldata.pivot('date','item')###减少了最后一个参数，变成了层次化的列

#####
#######
########数据转换
#####移除重复数据
data=pd.DataFrame({'k1':['one']*3+['two']*4,'k2':[1,1,2,3,3,4,4]})
data.duplicated() ##返回一个布尔值，判断各行是否是重复行
data.drop_duplicates()  ##移除重复行

data['v1']=range(7)
data.drop_duplicates(['k1']) ##指定行过滤重复项  ps 默认所有行都判断
data.drop_duplicates({'k1','k2'],take_last=True)  ###默认保留最后一个出现值的组合

###利用函数或映射进行数据转换
